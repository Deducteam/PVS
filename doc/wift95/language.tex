% Master File: language.tex
% Document Type: LaTeX

\def\stt{\smaller\tt}

\section{The \pvs\ Language}

The specification language of \pvs\ is a highly expressive language
based on higher-order logic.  The language was designed to describe
computer systems, but concentrates on abstract descriptions rather than
detailed prescriptions (\ie\ {\em what\/} rather than {\em how\/}).  The
language supports modularity and reuse by means of parameterized {\em
theories\/}, and has a rich type system, including the notion of a
{\em predicate subtype\/}.  This makes typechecking undecidable, but
provides a great deal of flexibility.  In addition, there are type
constructors for function, tuple, record, and abstract datatypes.

A theory consists of a sequence of {\em declarations\/}, which provide
names for types, constants, (logical) variables, axioms, and formulas.
These names may be overloaded; \eg\ {\tt +} may be declared to operate
on a newly declared type, and still be available for integer addition.
There is a large body of theories built into \pvs, collectively
referred to as the {\em prelude\/}.

In the following sections we will describe the language by means of a
series of examples.  These examples were chosen to exemplify various
aspects of the language, and do not necessarily reflect the best style.
The \pvs\ language is described in detail in ~\cite{PVS:language}.


\subsection{A Simple Example: The Rational Numbers}

The rational numbers are built into \pvs, but for the sake of
illustration we attempt to develop a partial axiomatization.  The
examples in this section illustrate some simple syntactic and semantic
aspects of \pvs\@.  They show how theories are defined containing
declarations of types, variables, and constants.  They also illustrate
the definition of types, subtypes, and constants, the declaration of
axioms and formulas, and the consequences of typechecking in the
presence of subtypes.  We start with the following theory introducing a
type {\stt rat}, a constant {\stt zero} of type {\stt rat}, and a binary
function {\tt /}.  These form the signature of the theory {\stt rats}.
\begin{pvsexample}
  rats: THEORY
   BEGIN
    rat : TYPE
    zero : rat
    / : [rat, rat -> rat]
   END rats
\end{pvsexample}
%
The type {\stt rat} is uninterpreted; the only assumption made by the
system is that it is nonempty.  Here the division function `{\tt
/}' takes two arguments of type {\stt rat} and returns a value of type
{\stt rat}.\footnote{The division symbol `{\tt /}' has already been
declared as an infix symbol in the \pvs\ grammar.}

The theory presented so far says little about the rational numbers; just
that there is a constant and a binary function defined on the type.  The
rationals are a model for this theory, but so are the booleans, the
integers, etc.\footnote{For example, we can interpret {\stt rat} as the
boolean type, {\stt zero} as {\sc false}, and {\tt /} as {\stt AND}.} The
next thing to do is to introduce axioms and definitions that further
constrain the possible interpretations of the theory.  We can
augment the {\stt rats} theory above as follows:
\begin{pvsexample}
  rats : THEORY
   BEGIN
    rat : TYPE
    zero : rat
    / : [rat, rat -> rat]
    * : [rat, rat -> rat]
    x, y: VAR rat
    left\_cancellation : AXIOM x * (y/x)  = y
    zero_times : AXIOM zero * x = zero
   END rats
\end{pvsexample}
%
In this augmented theory, we have introduced the declaration for the
multiplication operation `{\tt *},' the identifiers {\stt x} and {\stt y}
have been declared as logical variables that range over the type {\stt
rat}, and we have added two axioms asserting properties of
multiplication and division.

Though the {\stt left\_cancellation} axiom looks plausible, there is a
problem with it.  A reasonable ``challenge'' for our theory is the
conjecture {\tt (EXISTS y : y /= zero)}.\footnote{In \pvs, ``not equal''
is written as ``{\tt /=}''.} Unfortunately, we can easily prove {\stt
zero = y} for any {\stt y}, by substituting {\stt zero} for {\stt x} in
{\stt left\_cancellation}, and applying {\stt zero\_times} with {\stt
(y/x)} substituted for {\stt x}.  The conclusion {\stt zero = y} is
clearly not intended for a model of the rational numbers.  One way to
repair the problem is to qualify the {\stt left\_cancellation} axiom so
that it reads {\stt x /= zero IMPLIES x * (y/x) = y}. In this way, the
axioms make no restrictions on the value returned by division when given
a zero denominator.  This technique of having division by zero return
some unspecified value is the traditional approach used in logic and
mathematics, but can lead to problems in specifications since most
implementations prefer to treat this as an error condition, rather than
returning an arbitrary value.

To circumvent this problem, \pvs\ makes it possible to specify division
so that it is an error to apply it when the denominator is zero.  Here
is an improved \pvs\ specification:
\begin{pvsexample}
  rats : THEORY
   BEGIN
    rat : TYPE
    x, y : VAR rat
    zero : rat
    nonzero : TYPE = \{x | x /= zero\}
    / : [rat, nonzero -> rat]
    * : [rat, rat -> rat]
    left_cancellation : AXIOM zero /= x IMPLIES x * (y/x)  = y
    zero_times : AXIOM zero * x = zero
   END rats
\end{pvsexample}
%
Here the type {\stt nonzero} is defined to be the type of elements of
{\stt rat} that are different from {\stt zero}.  We call {\stt nonzero} a
{\em predicate subtype} of {\stt rat}, since it consists of the elements
of {\stt rat} satisfying a given predicate.  In this new specification,
the denominator argument may only range over the nonzero elements of the
type {\stt rat}.  In typechecking the occurrence of division in {\stt
left\_cancellation}, there is a {\em type correctness condition\/} (\tcc)
generated by the typechecker that is added to the theory as a
declaration:
\begin{pvsexample}
left_cancellation_TCC1: OBLIGATION
      (FORALL (x: rat): zero /= x IMPLIES x /= zero)
\end{pvsexample}
%
Notice that the logical antecedent governing the occurrence of division
is included as an antecedent of {\stt left\_cancellation\_TCC1}.  This
\tcc\ is of course easily proved.  In fact, if the antecedent were
written in the more natural form {\stt x /= zero}, the \tcc\ would not
have been generated.  \tccs\ such as this are {\em obligations\/}, and
they must be proved in order to show that the theory is type correct.
\pvs\ allows the proof of a \tcc\ to be deferred, but until it has been
discharged any proofs involving the theory {\stt rats} directly or
indirectly will be considered incomplete.

For a slightly more sophisticated example, we can introduce the
``less-than'' relation and the subtraction and unary minus operations,
along with a statement asserting a property of subtraction, division, and
the less-than ordering.\footnote{Note the overloading of the name {\stt -}.
All names of the same kind within a theory must be unique, with the
exception of expression kinds, which need only be unique up to the
signature. The signature is enough to distinguish these declarations.}
\begin{pvsexample}
  < : [rat, rat -> bool]
  - : [rat, rat -> rat]
  - : [rat -> rat]
  div_test: FORMULA x /= y IMPLIES (y-x)/(x-y) < zero
\end{pvsexample}
%
Notice here that the relation {\tt <} is declared as a function with
range type {\stt bool} representing the booleans\footnote{Functions
with range type {\tt bool} are often called {\em predicates\/} in PVS,
and are also used to represents sets.  Some convenient notation for
these interpretations is introduced later.} Typechecking the formula
{\stt div\_test} generates the \tcc\
\begin{pvsexample}
div_test_TCC1: OBLIGATION
    (FORALL (x:rat, y: rat): x /= y IMPLIES (x - y) /= zero)
\end{pvsexample}
%
An alternative notation for predicate subtypes is illustrated by another
example.  If the predicate {\stt non\_neg?} (we often use a question
mark in a name to indicate predicates) is defined as
\begin{pvsexample}
non_neg?(x): bool = NOT (x < zero)
\end{pvsexample}
%
then the expression {\stt (non\_neg?)} denotes a subtype with the same
meaning as the type expression {\stt \{x | NOT (x < zero)\}}.  The
function returning the absolute value of a rational can now be specified as
\begin{pvsexample}
abs(x): (non_neg?) = (IF (x < zero) THEN -x ELSE x ENDIF)
\end{pvsexample}
%
When typechecked, this definition generates the \tccs
\begin{pvsexample}
  abs_TCC1: FORMULA
    (FORALL (x: rat): (x < zero) IMPLIES non_neg?(-x))
  abs_TCC2: FORMULA
    (FORALL (x: rat): NOT (x < zero) IMPLIES non_neg?(x))
\end{pvsexample}
%
Note that the type of {\stt abs} is {\stt [rat -> (non\_neg?)]} which
is more informative than the type of {\stt [rat -> rat]}.  The advantage
of this is that whenever {\stt abs} occurs as an argument to a function
requiring a {\stt non\_neg?} argument, no new obligations are generated.
For example, a square root function {\stt sqrt} may be defined with type
{\stt [(non\_neg?) -> (non\_neg?)]} and freely applied to the result of
{\stt abs} without incurring any new obligations.\footnote{This is one of
the advantages of having predicate subtypes; in a logic of partial terms
we would be forced to show that the term involving {\stt sqrt} is
well-defined every time it occurs, or to somehow cache the information.}

Clearly, we still have an inadequate specification of rational numbers
since we do not have the axioms required to prove the various \tccs\ that
were generated.  We will not embark on the full axiomatization here, as
no new features of the language are involved.  The development of the
rational numbers is described in an appendix to the Language
Reference~\cite{PVS:language}.  It is important to note that the \pvs\
proof checker has an underlying decision procedure that automatically
proves many of the properties of the rational numbers.

Summarizing, we have illustrated how predicate subtypes can be used
to circumscribe the domain of partially defined operations such as
division, and to more usefully delineate the range of functions such as
{\stt abs}.  We also examined how the use of predicate subtypes in an
expression could require certain type correctness conditions to be
proved before the expression is regarded as well-typed.


\subsection{A More Sophisticated Example: Stacks}

Perhaps the most hackneyed specification example is that of stacks.  It
is interesting therefore to examine if \pvs\ can contribute anything
novel to this well-worn example.  For starters, let us try to capture
the signature of the stack operations.
\begin{pvsexample}
  stacks : THEORY
   BEGIN
    stack : TYPE
    empty : stack
    push : [nat, stack -> stack]
    top : [stack -> nat]
    pop : [stack -> stack]
   END stacks
\end{pvsexample}
%
In the theory {\stt stacks} above, {\stt nat} is the built-in type for
natural numbers, {\stt stack} is declared as an uninterpreted type,
and the {\stt empty} is an uninterpreted constant of type {\stt
stack}.  The function {\stt push} is declared to take a natural number
and a stack and return a stack.  The {\stt top} function takes a stack
and returns a natural number.  The {\stt pop} function takes a stack
and returns a stack.

One immediate objection is that the above declaration only specifies the
signature for stacks of natural numbers and is therefore not
sufficiently generic.  \pvs\ supports this by providing parameterization
at the theory level.\footnote{An alternative approach would allow type
variables and type abstraction in the language, but in the presence of
subtypes this greatly complicates the semantics.} With the {\stt stacks}
theory appropriately parameterized, we get
\begin{pvsexample}
  stacks [t : TYPE] : THEORY
   BEGIN
    stack : TYPE
    empty : stack
    push : [t, stack -> stack]
    top : [stack -> t]
    pop : [stack -> stack]
   END stacks
\end{pvsexample}
%
This declares a {\em schema\/} of stacks, one for each type.  Within the
{\stt stacks} theory {\stt t} is treated as a fixed uninterpreted type.
When the {\stt stacks} theory is used by another theory it must be
instantiated.  For example, the theory of stacks of natural number is
just {\stt stacks[nat]}.  It is important to note that each instantiation
of a theory yields a new signature; thus instantiating with {\stt int}
and {\stt nat} yields two different {\stt empty} constants.

The new signature is still unsatisfactory since the signatures for {\stt
pop} and {\stt top} permit expressions such as {\stt pop(empty)} and {\stt
top(empty)}, for which it is difficult to ascribe a meaning.  The
obvious solution in \pvs\ is to mimic what was done with division and
constrain the domains of {\stt pop} and {\stt top}.  We do this by
introducing the predicate {\stt nonemptystack?} in the new specification
below.  Note that the expression {\stt [stack -> bool]} for the type of a
predicate has been rewritten as the equivalent {\stt PRED[stack]}.  In
addition, we add the usual stack axioms: \label{abstractstack}
\begin{pvsexample}
  stacks [t: TYPE] : THEORY 
   BEGIN
    stack : TYPE
    nonemptystack? : PRED[stack]
    s : VAR stack
    x, y : VAR t
    ns : VAR (nonemptystack?)
    empty : stack
    push : [t, stack -> (nonemptystack?)]
    top : [(nonemptystack?) -> t]
    pop : [(nonemptystack?) -> stack]
    pop_push : AXIOM pop(push(x, s)) = s
    top_push : AXIOM top(push(x, s)) = x
    push_pop_top : AXIOM  push(top(ns), pop(ns)) = ns
    push_empty : AXIOM empty /= push(x, s)
    nonempty_empty : THEOREM NOT nonemptystack?(empty)
    pop2_push2 : THEOREM pop(pop(push(x, push(y, s)))) = s   
   END stacks 
\end{pvsexample}

Now we can explore the consequence of this specification by examining
the formula declaration {\stt pop2\_push2}.  The left-hand side
expression of this formula poses a problem for most type systems since
the type of {\stt pop(push(x, (push(y, s))))} (i.e., the argument to
the outermost {\tt pop}) is {\stt stack}, whereas the domain type of
{\stt pop} is the more constrained {\stt (nonemptystack?)}.  In \pvs,
the typechecker generates the \tcc\
\begin{pvsexample}
  pop2_push2_TCC1: OBLIGATION
    (FORALL (s: stack, x: t, y: t):
       nonemptystack?(pop(push(x, push(y, s)))))
\end{pvsexample}
This \tcc\ is easily proved from the axiom {\stt pop\_push}.

We have now presented an abstract specification of stacks, showing how
theories may be parameterized and further illustrating the subtype
mechanism.  In the following section we will explore different
constructive definitions of stacks, and in Section~\ref{datatypes} we
will see how to define stacks as an abstract datatype.


\subsection{Implementing Stacks}

Having satisfied ourselves that stacks can be specified using the
signature and axioms above, we might wish to introduce an alternative,
more definitional specification of stacks.  In this new specification,
we implement a stack with two components: a counter for recording the
number of elements in the stack, and an array containing the stack
entries.  One way to implement such a stack in \pvs\ is to use the tuple
type constructor and another is to employ records.  We examine both
approaches below.

\begin{pvsexample}
  newstacks [t: TYPE] : THEORY 
   BEGIN
    i, j: VAR nat
    stack : TYPE = [ nat, ARRAY[nat -> t] ]
    s: VAR stack
    x, y: VAR t
    size(s): nat = proj\_1(s)
    elements(s): ARRAY[nat -> t] = proj\_2(s)
    e: t
    nonemptystack?(s) : bool = (size(s) > 0)
    empty: stack = (0, (LAMBDA j: e))
    push(x,s): (nonemptystack?) =
      (size(s)+1, elements(s) WITH [(size(s)):=x])
    ns: VAR (nonemptystack?)
    top(ns): t = elements(ns)(size(ns)-1)
    pop(ns): stack = (size(ns)-1, elements(ns))
   END newstacks 
\end{pvsexample}
%
There are several points to note about the above specification.  The
2-tuple implementing stacks is specified by the type {\stt [nat, ARRAY
[nat -> t]]} whose first component is a natural number and whose
second component is an array with index type {\stt nat} and element
type {\stt t}.  The array type expression {\stt ARRAY[nat -> t]} is
identical to the function type expression {\stt [nat -> t]} and the
{\stt ARRAY} keyword serves a descriptive rather than semantic
purpose.  The built-in family of {\stt proj} functions serve to access
tuple components.  The function {\stt size} is defined to return the
size of stack {\stt s} which is defined to be the first component of
{\stt s}, namely, {\stt proj\_1(s)}.  The stack elements are
``stored'' in the array that is the second component of stack {\stt
s}, so that {\stt elements(s)} is defined as {\stt proj\_2(s)}.  The
{\stt size} function could also have been defined by the declaration
\begin{pvsexample}
size: [stack -> nat] = proj_1
\end{pvsexample}
%
which is merely a consequence of applying the extensionality axiom of
higher-order logic to the earlier definition of {\stt size}.  The next
thing to note is that if the size of the stack is {\stt i}, for {\stt i >
0}, then the {\stt i} stack values are stored in the indices {\stt 0} to
{\stt i-1}.  A stack expression is constructed by means of a pair of
comma-separated expressions enclosed in parentheses, so that the empty
stack is constructed by the expression {\stt (0, (LAMBDA j:\ e))} whose
size component is {\stt 0}, and where the {\stt elements} array is
initialized to contain a default element {\stt e}.  The {\stt push}
operation applied to an element {\stt x} and a stack {\stt s} constructs a
stack with size {\stt size(s) + 1}, where the {\stt size(s)} index of the
{\stt elements} array of {\stt s} has been updated to be {\stt x}.  The
{\em function update\/} is done by the {\stt WITH} construct as used in
{\stt elements(s) WITH [(size(s)):=x]}.  Correspondingly, the {\stt pop}
operation decrements the stack size by one, but leaves the {\stt
elements} array unchanged.  Note that we have used predicate subtyping
to ensure that {\stt pop} is only applied to stacks of positive size,
\ie\ nonempty stacks.  The {\stt top} operation applied to a nonempty
stack {\stt ns} returns the {\stt (size(ns)-1)}th element of the array
{\stt elements(ns)}.

The above specification of stacks when implemented using the record type
construction of \pvs\ rather than tuples, has the following form.
\begin{pvsexample}
  newstacks [t: TYPE] : THEORY 
   BEGIN
    i, j: VAR nat
    stack : TYPE = [# size: nat, elements : ARRAY[nat -> t] #]
    s: VAR stack
    x,y: VAR t
    e: t
    nonemptystack?(s) : bool = (size(s) > 0)
    empty : stack = (# size := 0, elements := (LAMBDA j: e) #)
    push(x,s): (nonemptystack?) =
       (# size:= size(s)+1,
          elements := elements(s) WITH [(size(s)):=x] #)
    ns: VAR (nonemptystack?)
    top(ns): t = (elements(ns)(size(ns)-1))
    pop(ns): stack = (ns WITH [size := size(ns) -1])
   END newstacks 
\end{pvsexample}
%
In this new specification of stacks, the record type is constructed by
the type expression {\stt [\# size:\ nat, elements :\ ARRAY[nat -> t] \#]}
with fields {\stt size} and {\stt elements}.  The expression {\stt (\#
size := 0, elements := (LAMBDA j:\ e) \#)} constructs the empty stack.
This specification is slightly more pleasing than the one using tuples
since the {\stt size} and {\stt elements} functions were automatically
generated from the record labels, and record updating can be used to
concisely define the {\stt pop} operation.

There is a problem with both versions of {\stt newstacks}  that
has to do with stack equality.  If we consider {\stt newstacks[nat]},
\ie\ stacks of natural numbers, then both
{\stt (\# size := 0, elements := (LAMBDA i:\ 1) \#)} and
{\stt (\# size := 0, elements := (LAMBDA i:\ 2) \#)} represent
empty stacks, but they are unequal since they differ on
their elements field.  Similarly, with this representation,
the formula {\stt pop(push(x, s)) = s} fails to be a theorem, since the
{\stt elements} array may differ at elements beyond {\stt size}.
We defer the discussion of this problem
and its solution to Section~\ref{dependent-typing}.

To summarize the discussion of the \pvs\ language so far, we have
examined theories, declarations and definitions of types and
constants, declarations of axioms and formulas, predicate subtypes and
the generation of type correctness conditions, and the definition,
construction and use of tuple and record types.  So far we have only
made limited use of higher-order logic by using a function object to
model the array that is used to contain the elements of a stack.  We
next examine the use of theories in \pvs\@.


\subsection{Using Theories: Partial and Total Orders}
\label{using-theories}

There are several reasons for structuring specifications into
(parameterized) theories as is done in \pvs\@.  The primary ones are
that it provides for modularization, and the use of parameters allows
more generic specifications, as we saw with stacks.  In this section, we
focus on the use and parameterization of theories.

A preliminary example of theory is that of partial orders as
transcribed in \pvs\ below.\footnote{This is built in to \pvs\ in a
different form; again, the development here is for pedagogical
purposes. Note the use of ``;'' to terminate the definition of {\stt
antisym}. Semicolons are optional, except in circumstances such as
this when the parser needs more information.  In this case, the
semicolon informs the parser that the operator {\stt <} is a
declaration rather than part of the preceding expression.}
\begin{pvsexample}
  partial_order [t: TYPE] : THEORY
   BEGIN
    <= : PRED[[t,t]]
    x, y, z: VAR t
    refl: AXIOM x <= x
    trans: AXIOM  x <= y AND y <= z IMPLIES x <= z
    antisym: AXIOM x <= y AND y <= x IMPLIES x = y;
    < : PRED[[t,t]] = (LAMBDA x, y: x <= y AND x /= y)
   END partial_order
\end{pvsexample}
%
Note that the type of a binary relation, such as {\stt <=}, can be given
either as {\stt [t, t -> bool]}, or as a predicate on the tuple {\stt
[t, t]}, as illustrated above.
For any type {\stt t}, the theory {\stt partial\_order} introduces a
partial order relation `{\stt <=}' with the axioms of reflexivity,
transitivity, and antisymmetry.  It also introduces a strict partial
order relation `{\stt <}' along with its definition. 

The next example is the theory of total ordering which extends the
original theory {\stt partial\_order}.
\begin{pvsexample}
  total_order [t: TYPE] : THEORY
   EXPORTING ALL WITH partial_order[t]
   BEGIN
    IMPORTING partial_order[t]
    x, y: VAR t
    total: AXIOM  x <= y OR y <= x
   END total_order
\end{pvsexample}
%
There are several points to note with {\stt total\_order}.  It {\em
imports\/} the theory {\stt partial\_order[t]} with the {\stt
IMPORTING} construct.  It would have also been acceptable to import
the generic theory {\stt partial\_order} since the typechecker is able
to resolve the type of the occurrences of {\stt <=} in {\stt
total\_order} as belonging to {\stt partial\_order[t]}.  The {\stt
EXPORTING} clause that precedes the body of the theory (as marked by
{\stt BEGIN}) causes every type, constant, and formula declaration in
{\stt total\_order} to be visible in any theory that imports {\stt
total\_order}.  In addition to the declarations in {\stt
total\_order}, the {\stt EXPORTING} clause also makes visible those
declarations in {\stt partial\_order[t]} that are externally visible.
When there is no {\stt EXPORTING} clause, the default is that all
declarations\footnote{With the exception of variable declarations.}
are visible, including all instances of imported theories that were
referenced.\footnote{When a generic theory is imported, the
typechecker determines the instance for each reference to an
entity declared in the generic theory---it is these instances that are
exported.} Generic theories cannot be exported, \ie\ it is not
possible to replace {\stt partial\_order[t]} in the {\stt EXPORTING}
clause with {\stt partial\_order}.

%\memo{Explain this.}

\subsection{Using Theories: Sort}

The next series of examples illustrate the use of the {\stt
partial\_order} and {\stt total\_order} theories in several ways.  These
examples provide a generic specification of what it means for an array
to be sorted.
\begin{pvsexample}
  sort [domain, range: TYPE] : THEORY
   BEGIN
    IMPORTING partial_order[range], total_order[domain]
    Array_type: TYPE = ARRAY[domain -> range]
    A, B, C: VAR Array_type
    sorted?(A): bool =
      (FORALL (x, y: domain): x < y IMPLIES NOT (A(y) <= A(x)))
   END sort
\end{pvsexample}
%
The above theory is parameterized with respect to the types {\stt
domain} and {\stt range}.  It imports the theories {\stt
partial\_order[range]} and {\stt total\_order[domain]}.  The predicate
{\stt sorted?} on arrays of element type {\stt range} and index type
{\stt domain} is defined to check that the partial ordering on the
elements never violates the total ordering on the indices.  Note that
the types of the predicates {\stt <} and {\stt <=} are potentially
ambiguous since
they could come from either {\stt partial\_order[range]} and {\stt
total\_order[domain]} but the typechecker resolves their types from the
context of their application.  If it was not possible to resolve the
ambiguity from the context, then it would have been necessary to write
{\stt <} as {\stt total\_order[domain].<} in order to distinguish it
from {\stt partial\_order[domain].<}.

One immediate problem with the above specification of sortedness is that
it is specified with respect to a fixed total ordering on the indices
and a fixed partial order on the elements of the array.  It is therefore
not sufficiently generic.  The following revised specification of the
theory {\stt sort} fixes this problem.  It does this by taking the domain
and range orderings as parameters but then places restrictions that
constrain the domain ordering to be total and the range ordering to be
partial.  These restrictions are listed in the {\stt ASSUMING} part
between the keywords {\stt ASSUMING} and {\stt ENDASSUMING}.  The assuming
part can only contain variable declarations and assumptions.  These
assumptions have to be discharged whenever the theory is instantiated
with actual parameters.  These proof obligations are automatically
generated by the typechecker.
\begin{pvsexample}
  sorta [domain, range: type, 
         d_order: PRED[[domain, domain]],
         r_order: PRED[[range, range]]] : THEORY
   BEGIN
    ASSUMING
     x, y, z: VAR domain
     u, v, w: VAR range
     d_refl: ASSUMPTION d_order(x,x)
     d_trans: ASSUMPTION  d_order(x, y) & d_order(y, z) => d_order(x, z)
     d_antisym: ASSUMPTION d_order(x, y) & d_order(y, x) => x = y
     d_total: ASSUMPTION  d_order(x, y) OR d_order(y, x)
     r_refl: ASSUMPTION r_order(u, v)
     r_trans: ASSUMPTION  r_order(u, v) & r_order(v, w) => r_order(u, w)
     r_antisym: ASSUMPTION r_order(u, v) & r_order(v, u) => u = v
    ENDASSUMING
    Array_type: TYPE = ARRAY[domain->range]
    A, B, C: VAR Array_type
    sorted?(A): bool =
      (FORALL (x, y: domain):
         (d_order(x, y) & x /= y) => NOT r_order(A(y), A(x)))
   END sorta
\end{pvsexample}

The above specification of sortedness might seem a little tedious given
that we have already specified partial and total orderings.  This points
to difficulties in the original specifications for {\stt partial\_order}
and {\stt total\_order}.  In the first place, the constant `{\stt <=}'
is declared in the {\stt partial\_order} theory; in general there is
already a relation at hand, and the desire is to check that it is a
partial order.  So we would like `{\stt <=}' to be a parameter to the
theory.  But now the axioms are inappropriate; if the theory is
parameterized with `{\stt /=}', for example, then we have an
inconsistency.  There are two possible approaches to this.  One is to
only allow the theory to be parameterized with relations that satisfy
the axioms.  This is done by means of an {\stt ASSUMING} part:
\begin{pvsexample}
  partial_order1 [t: TYPE, <=: PRED[[t,t]]] : THEORY
   BEGIN
    ASSUMING
     x, y, z: VAR t
     refl: ASSUMPTION x <= x
     trans: ASSUMPTION  x <= y AND y <= z IMPLIES x <= z
     antisym: ASSUMPTION x <= y AND y <= x IMPLIES x = y
    ENDASSUMING
    < : PRED[[t,t]] = (LAMBDA x, y: x <= y AND x /= y)
   END partial_order1
\end{pvsexample}
%
Now if the theory is instantiated with `{\stt /=}', the typechecker will
generate proof obligations which will be impossible to prove; thus such
an instantiation is disallowed.

The alternative is to declare higher-order predicates instead of axioms:
\begin{pvsexample}
  partial_order2 [t: TYPE] : THEORY
   BEGIN
    <= : VAR PRED[[t,t]]
    x, y, z: VAR t
    reflexive?(<=): bool = (FORALL x: x <= x)
    transitive?(<=): bool =
      (FORALL x,y,z: x <= y AND y <= z IMPLIES x <= z)
    antisymmetric?(<=): bool =
      (FORALL x,y: x <= y AND y <= x IMPLIES x = y)
   END partial_order2
\end{pvsexample}
%
The advantage of this theory is that it allows us to test directly the
properties of a given relation.  The disadvantage is the the `{\stt <}'
relation must be defined outside.  The real advantage comes in being
able to combine properties, and use them as types. For example we can
add the declaration
\begin{pvsexample}
  partial_order?(<=): bool =
    reflexive?(<=) AND transitive?(<=) AND antisymmetric?(<=)
\end{pvsexample}
%
and declare a relation {\stt R} to be a variable ranging over partial
orders on the type integer:
\begin{pvsexample}
  R: VAR (partial_order?[int])
\end{pvsexample}

We exploit this in the next theory specification, which describes the
various ordering relations as predicates on relations.  The {\stt
orderings} theory introduces an infix {\em variable\/} {\stt <=} which
is a reasonable thing to do in a higher-order logic.  Now notice that
the predicates {\stt reflexive?}, {\stt antisymmetric?}, {\stt
transitive?}, etc., are higher-order operations since they are
predicates on predicates.  The important concept of well-foundedness is
also introduced in the theory below.  A partial order {\stt <=} is said
to be well-founded on a set $A$ if $A$ contains no infinitely descending
chain of elements $\ldots \mbox{\tt <=} x_n \mbox{\tt <=} \ldots
\mbox{\tt <=} x_1 \mbox{\tt <=} x_0$.  Another way of stating this is
that every nonempty subset of $A$ must contain a minimal element with
respect to {\stt <=}.  In terms of higher-order logic, for every
predicate {\stt qq} on {\stt t} that holds somewhere (\ie\ is nonempty),
there is a minimal element that satisfies {\stt qq}.

\begin{pvsexample}
  orderings[t: TYPE] : theory
   BEGIN
    x, y, z: VAR t
    pp, qq: VAR PRED[t]
    <= : VAR PRED[[t,t]]
    reflexive?(<=): bool =  (FORALL x: x <= x)
    antisymmetric?(<=): bool = (FORALL x, y: x <= y AND y <= x IMPLIES x = y)
    transitive?(<=): bool =
      (FORALL x, y, z: x <= y AND y <= z IMPLIES x <= z)
    partial_order?(<=): bool =
      reflexive?(<=) AND antisymmetric?(<=) AND transitive?(<=)
    linear?(<=): bool = (FORALL x, y: x <= y OR y <= x)
    total_order?(<=): bool = partial_order?(<=) AND linear?(<=)
    well_founded?(<=): bool =
      (FORALL qq: (EXISTS y: qq(y))
           IMPLIES (EXISTS (y: (qq)): (FORALL (x: (qq)): NOT x<=y)))
   END orderings
\end{pvsexample}

Now we can give yet another specification of sortedness.  The
interesting thing to note here is the occurrence of an {\stt IMPORTING}
clause in the parameter list of the theory to bring in the information
that is needed to typecheck the remaining parameters.
\begin{pvsexample}
  sorto [domain, range: type,
         (IMPORTING orderings)
         d_order: (total_order?[domain]),
         r_order: (partial_order?[range])] : THEORY
   BEGIN
    Array_type: TYPE = ARRAY[domain->range]
    A, B, C: VAR Array_type
    sorted?(A): bool =
      (FORALL (x, y: domain): (d_order(x, y) AND x/=y)
                      IMPLIES NOT r_order(A(y), A(x)))
   END sorto
\end{pvsexample}

Another thing one can do with the {\stt orderings} theory is define
well-founded induction which is a standard proof technique for proving
properties of programs.  The key idea is that if we are trying to
prove {\stt pp(x)} for all {\stt x} of type {\stt t}, and there is a
well-founded ordering {\stt <=} on {\stt t}, then we can reason as
follows.  Consider the subset of elements {\stt y} of {\stt t} such
that {\stt NOT pp(y)} holds.  Suppose that this set is nonempty, then
by well-foundedness, this subset must contain a minimal element {\stt
z}, but the hypothesis of {\stt well\_founded\_induction} can be used
to derive {\stt pp(z)} since {\stt (FORALL y:\ y <= z AND y /= z
IMPLIES pp(y))} holds trivially for a minimal element {\stt z}.  Thus
both {\stt pp(z)} and {\stt NOT pp(z)} hold, contradicting the
assumption that the set of {\stt y} such that {\stt NOT pp(y)} is
nonempty.
\begin{pvsexample}
  well_founded_induction [t: type,
                 (IMPORTING orderings[t])
                 <= : (well_founded?)] : THEORY
   BEGIN
    x, y, z: VAR t
    pp: VAR PRED[t]
    wf_induction: AXIOM
      (FORALL x: (FORALL y: y<=x AND y/= x IMPLIES pp(y))
                 IMPLIES pp(x))
      IMPLIES (FORALL x: pp(x))
   END well_founded_induction
\end{pvsexample}

The {\stt well\_founded\_induction} theory makes use of higher-order
logic to assert the given ordering {\stt <=} to be well-founded, and
to state induction as an axiom for any predicate {\stt pp}.

As we did in the case of ordering relations, we can build a theory
defining various properties of functions in order to further illustrate
the capabilities of higher-order logic as formalized by \pvs\@.\footnote
{Both well-founded induction and functions are built in to the \pvs\
prelude (theories {\stt wf\_induction} and {\stt functions}, respectively)
and may not be redefined, hence the name variations introduced here.}
\begin{pvsexample}
  functions_ [domain, range : type] : THEORY
   BEGIN
    fun : VAR [domain -> range]
    x, y : VAR domain
    injective?(fun): bool = (FORALL x, y : fun(x) = fun(y) IMPLIES x=y)
    surjective?(fun): bool = (FORALL (u : range): (EXISTS x : fun(x) = u))
    bijective?(fun): bool = injective?(fun) AND surjective?(fun)
   END functions_
\end{pvsexample}
%
If we then introduce a function as an injection, the PVS typechecker will
require that we demonstrate that its definition indeed satisfies the
predicate {\tt injective?}.  For example
\begin{pvsexample}
  square [(IMPORTING functions_) domain, range : TYPE] : THEORY
   BEGIN
    x: VAR int
    square: (injective?[int, nat]) = (LAMBDA (x): x * x)
   END square
\end{pvsexample}
{\stt square} generates an unprovable \tcc\, thereby revealing an
error in this construction.

Summarizing, we have examined some more advanced capabilities of the
language and logic of \pvs\@.  The parameterization and use of
theories was illustrated in all the examples in this section.  The
theories {\stt orderings}, {\stt well\_founded\_induction}, and {\stt
functions\_} illustrate the higher-order aspects of the logic as well.
We also noted the capability of the typechecker in resolving
ambiguities in naming from the application context.

\subsection{Sets in Higher-order Logic}
\label{sets-in-hol}

In this section, we expand on the capabilities of higher-order logic
with a naive encoding of the various set-theoretic operations.  We
stay consistent with the higher-order logic view of sets as predicates.
In this case the theory {\stt sets\_} is parameterized so that we are
talking about predicates over a type {\stt T}.  The element {\stt x} is a
member of a set {\stt a} if and only if {\stt a(x)} is {\stt TRUE}.  The
{\stt union} and {\stt add} operation is defined in terms of disjunction
({\stt OR}), and the intersection and difference operations are defined
in terms of conjunction ({\stt AND}).  The extensionality axiom asserts
that if sets {\stt a} and {\stt b} have exactly the same members, then
they are equal.  Extensionality for sets can be proved from
extensionality for functions so it is stated below as a lemma.
\begin{pvsexample}
  sets_ [T: TYPE] : THEORY
   BEGIN
    set: TYPE = SETOF[T]
    member(x:T,a:set): bool = a(x)
    union(a,b:set): set = {x:T | member(x,a) OR member(x,b)}
    intersection(a,b:set): set = {x:T | member(x,a) AND member(x,b)}
    difference(a,b:set) : set = {x:T | member(x,a) AND NOT member(x,b)}
    add(x:T,a:set) : set = {y:T | x = y OR member(y,a)}
    singleton(x:T) : set = {y:T | y = x}
    subset?(a,b:set) : bool = (FORALL (z:T) : member(z,a) => member(z,b))
    strict_subset?(a,b:set) : bool = subset?(a,b) AND a /= b
    empty?(a:set) : bool = (FORALL (x:T) : NOT member(x,a))
    emptyset: set = {x:T | FALSE}
    fullset: set = {x:T | TRUE}
    extensionality: LEMMA
      FORALL (a,b: set):
        (FORALL (x:T): member(x,a) = member(x,b)) => (a = b)
   END sets_
\end{pvsexample}

Sequences provide yet another nice illustration of the power of the
\pvs\ higher-order logic.  We can formalize infinite sequences of
elements from some type {\stt T} as functions of type {\stt [nat ->
T]}, where {\stt nat} is the type of natural numbers.  Then the {\stt
n}th element of a sequence {\stt seq} is just {\stt seq(n)}.  The
sequence that is obtained from {\stt seq} by removing the first {\stt
n} elements is defined as {\stt suffix(seq, n)}.
\begin{pvsexample}
  sequences_[T: TYPE] : THEORY
   BEGIN
    sequence : TYPE = [nat->T]
    nth(seq: sequence, n: nat): T = seq(n)
    suffix(seq:sequence, n:nat): sequence =
      (LAMBDA (i:nat): seq(i+n))
    first(seq: sequence): T = nth(seq, 0)
    rest(seq: sequence): sequence = suffix(seq, 1)
   END sequences_
\end{pvsexample}
%
Both sets and sequences are employed heavily in specification
writing and are built in to the \pvs\ prelude.\footnote{\pvs\ prelude
theories may be viewed via the command {\tt M-x view-prelude-theory}
({\tt M-x vpt}). The command {\tt M-x view-prelude-file} ({\tt M-x vpf})
displays the entire prelude.}

\subsection{Recursion}

In this section we discuss recursive declarations.  We start with a
simple example, the factorial function:
\begin{pvsexample}
  factorial(x:nat): RECURSIVE nat =
    IF x = 0 THEN 1 ELSE x * factorial(x - 1) ENDIF
    MEASURE (LAMBDA (x:nat): x)
\end{pvsexample}
%
This is similar to a constant declaration, except that the defining
expression references {\stt factorial}, which is the function being
defined.  In addition, there is a {\stt MEASURE} function specified.
In \pvs, all definitions are total, and form a conservative
extension.\footnote{This means that (new) inconsistencies are not
introduced as a
result of adding a new definition.} In order to guarantee these
conditions, a {\stt MEASURE} function is required.  This function has the
same domain as the definition, but its range is {\stt nat}.\footnote{The
range may be the constructive ordinals instead, but we will not be
discussing that further here.} The {\stt MEASURE} function is used to
show that the definition terminates, by generating an obligation that
the {\stt MEASURE} decreases with each call:
\begin{pvsexample}
  factorial_TCC2: OBLIGATION
    (FORALL (x: nat): NOT x = 0 IMPLIES x - 1 < x)
\end{pvsexample}
%
Note that the context `{\stt NOT x = 0}' is included in the {\em
termination\/} \tcc.  \pvs\ does not allow mutual recursion directly,
although the same effect may be had by using axioms or by translating
the mutually recursive forms to higher order, so this is not a real
restriction.


\subsection{Dependent Typing}
\label{dependent-typing}

In this section, we illustrate a more sophisticated form of typing that
can involve dependencies between the components of a tuple or a record
type, and also between the range and domain of a function type.  As we
have already seen, predicate subtyping makes it possible to express
properties within the type language, and dependent typing significantly
enhances this capability.

To explore dependent typing, we return to the example of {\stt
newstacks}.  There the type {\stt stack} was defined as the record type
{\stt [\# size:\ nat, elements :\ ARRAY[nat -> t] \#]}.  We noted that this
specification would distinguish between two empty stacks simply because
they contained different {\stt elements} arrays, even though the contents
of the {\stt elements} array are irrelevant when the the {\stt size} field
is {\stt 0}.  What we would like is to specify a record with two fields,
{\stt size} and {\stt elements}, where the type of the {\stt elements}
field varied according to the contents of the {\stt size} field.  We can
in fact express such a record type in \pvs\ so that the definition of
the type {\stt stack} becomes
\begin{pvsexample}
  stack : TYPE =
      [# size: nat, elements : ARRAY[{i| i<size} -> t] #]
\end{pvsexample}
%
Note that the index type of the {\stt elements} array has been restricted
to the natural numbers below the contents of the {\stt size} field.  Such
a record type is an instance of a {\em dependent type\/}.  With this
form of dependent typing, the {\stt newstacks} specification can be
written in \pvs\ as follows.
\begin{pvsexample}
  newstacks [t: TYPE] : THEORY 
   BEGIN
    i: VAR nat
    stack : TYPE = [# size: nat, elements: ARRAY[\{i| i<size\} -> t] #]
    s: VAR stack
    x,y: VAR t
    e: t
    nonemptystack?(s) : bool = (size(s) > 0)
    empty: stack =
      (# size := 0, elements := (LAMBDA (j: \{i|i<0\}): e) #)
    push(x,s): (nonemptystack?) =
      (# size:= size(s)+1,
         elements := elements(s) WITH [(size(s)):=x] #)
    ns: VAR (nonemptystack?)
    pop(x,ns): stack = 
      (# size := size(ns) -1,
         elements := (LAMBDA (j: {i|i<size(ns)-1}):
                     elements(ns)(j)) #)
    top(ns): t = (elements(ns)(size(ns)-1))
   END newstacks 
\end{pvsexample}

There are a number of subtleties to the above specification.  The {\stt
empty} stack contains an {\stt elements} array with an empty index type.
Now any two stacks with the {\stt size} field set to zero will be equal
since any element arrays will be treated as equal when compared over
the empty index type.

The value returned by the {\stt push} operation is a stack where the size
field is one greater than that of the input stack.  The type of the {\stt
elements} field of this stack is therefore different from that of the
input stack.  There is an additional index where the {\stt elements}
array must be defined, and the update operation (using the {\stt WITH}
construct) ensures that the {\stt elements} field is in fact defined on
this additional index.

The value returned by the {\stt pop} operation is a stack in which
the size field is one less than that of the input stack and the
{\stt elements} array is defined on one fewer indices.\footnote
{A slightly abbreviated form of the {\stt LAMBDA} expression:
\texttt{(LAMBDA (i|i<size(ns)-1): elements(ns)(i))}
is also possible.  To appreciate the subtlety of this example, note
the considerable care necessary when constructing a new record of type
{\stt stack} to insure that the domains of {\stt elements} match
properly.}  Given these definitions, the formula {\stt pop(push(x, s)) = s}
is provable.

\subsection{Abstract Datatypes: Stacks}
\label{datatypes}

In this section we describe one of the more powerful features of the
\pvs\ language: abstract datatypes.  We will once again be using stacks
for illustrative purposes.

The abstract {\stt stacks} theory of Section~\ref{abstractstack} contains
axioms providing the
usual algebraic specification of stacks.  However, \pvs\ has a mechanism
for automatically generating a complete axiomatization for such a theory
from a very succinct
description.  Thus an alternative specification for stacks would be
\begin{pvsexample}
  stack [t: TYPE]: DATATYPE
   BEGIN
    empty: emptystack?
    push(top: t, pop: stack) : nonemptystack?
   END stack
\end{pvsexample}
Notice that the keyword {\stt DATATYPE} distinguishes this from an
ordinary {\stt THEORY}.
In this specification, {\stt empty} and {\stt push} are {\em
constructors\/}, {\stt top} and {\stt pop} are {\em accessors\/}, and {\stt
emptystack?} and {\stt nonemptystack?} are {\em recognizers\/} of the
parameterized {\stt stack} type.  In addition to generating the
signatures given in the previous {\stt stacks} theory, this specification
automatically generates a new theory (and file) called {\stt stack\_adt}
containing\footnote{Disjointness and inclusion axioms are not explicitly
generated, but are built in to the prover (principally through the semantics
of induction and the case construct).}:

\begin{itemize}
\item Extensionality axioms for the constructors, \eg
\begin{pvsexample}
  stack_push_extensionality: AXIOM
    (FORALL (nonemptystack?_var: (nonemptystack?),
             nonemptystack?_var2: (nonemptystack?)):
       top(nonemptystack?_var) = top(nonemptystack?_var2)
         AND pop(nonemptystack?_var) = pop(nonemptystack?_var2)
         IMPLIES nonemptystack?_var = nonemptystack?_var2);
\end{pvsexample}

\item An eta axiom:
\begin{pvsexample}
  stack_push_eta: AXIOM
        (FORALL (nonemptystack?_var: (nonemptystack?)):
           push(top(nonemptystack?_var), pop(nonemptystack?_var))
             = nonemptystack?_var);
\end{pvsexample}

\item Accessor/constructor axioms, \eg
\begin{pvsexample}
   stack_pop_push: AXIOM
     (FORALL (push1_var: t, push2_var: stack):
       pop(push(push1_var, push2_var)) = push2_var);
\end{pvsexample}

%\item A disjointness axiom stating that no stack may be both empty and
%nonempty:
%\begin{pvsexample}
%   stack_disjoint: AXIOM
%     (FORALL (stack_var: stack):
%       NOT (emptystack?(stack_var) AND nonemptystack?(stack_var)))
%\end{pvsexample}

%\item An inclusion axiom stating that every stack must be either empty
%or nonempty:
%\begin{pvsexample}
%   stack_inclusive: AXIOM
%     (FORALL (stack_var: stack):
%       emptystack?(stack_var) OR nonemptystack?(stack_var));
%\end{pvsexample}

\item An induction scheme:
\begin{pvsexample}
  stack_induction: AXIOM
    (FORALL (p: [stack -> boolean]):
       p(empty) AND
         (FORALL (push1_var: t, push2_var: stack):
            p(push2_var) IMPLIES p(push(push1_var, push2_var)))
         IMPLIES (FORALL (stack_var: stack): p(stack_var)));
\end{pvsexample}

\item Functions distributing predicates over the stack base type\footnote{
      These functions are available both in curried form (shown above)
      and uncurried form.}:
\begin{pvsexample}
  every(p: PRED[t])(a: stack): boolean =
    CASES a OF
      empty: TRUE,
      push(push1_var, push2_var):
          p(push1_var) AND every(p)(push2_var)
      ENDCASES

  some(p: PRED[t])(a: stack): boolean =
    CASES a OF
      empty: FALSE,
      push(push1_var, push2_var):
          p(push1_var) OR some(p)(push2_var)
      ENDCASES
\end{pvsexample}

\item A subterm function:
\begin{pvsexample}
  <<(x: stack, y: stack): boolean =
    CASES y OF
      empty: FALSE,
      push(push1_var, push2_var): x = push2_var OR x << push2_var
    ENDCASES
\end{pvsexample}

\item A well-foundedness axiom:
\begin{pvsexample}
  stack_well_founded: AXIOM well_founded?[stack](<<);
\end{pvsexample}

\item A recursive combinator\footnote{Another function, {\stt reduce\_ordinal},
that reduces a stack to an ordinal rather than a natural number
is also generated.}:
\begin{pvsexample}
reduce_nat(emptystack?_fun: nat, nonemptystack?_fun: [[t, nat] -> nat]):
 [stack -> nat] =
  LAMBDA (stack_var: stack):
   CASES stack_var OF
    empty: emptystack?_fun,
    push(push1_var, push2_var):
      nonemptystack?_fun(push1_var,
                         reduce_nat(emptystack?_fun,
                                       nonemptystack?_fun)
                           (push2_var))
   ENDCASES
\end{pvsexample}

The recursive combinator allows the specification of functions such as
{\stt length}\footnote{In order to preserve soundness, PVS requires all
user-defined recursive functions to include a {\em measure\/}, which
is used to generate termination conditions.  The primary use of the
recursive combinator is to build measure functions for recursive
definitions.  (Measure functions themselves cannot usually be defined
by recursive definitions, since those definitions require an existing
measure function.)}:
\begin{pvsexample}
   length(s:stack): nat =
     reduce_nat(0, (LAMBDA (x:t, n:nat): n + 1))(s)
\end{pvsexample}

\item In addition to the recursive combinator used above (which is
specialized to the construction of measure functions), a fully general
recursive combinator is generated in a separate parameterized theory
named {\stt stack\_adt\_reduce}.

\item Another separate parameterized theory, providing a mapping function
on stacks, is also generated\footnote{The map function is also available
in curried form (shown above) and uncurried form.}:
\begin{pvsexample}
  stack_adt_map[t: TYPE, t1: TYPE]: THEORY
    BEGIN
  
    IMPORTING stack_adt
  
    map(f: [t -> t1])(a: stack[t]): stack[t1] =
      CASES a OF
        empty: empty[t1],
        push(push1_var, push2_var):
            push[t1](f(push1_var), map(f)(push2_var))
      ENDCASES
 
    END stack_adt_map
\end{pvsexample}

\end{itemize}

\subsection{Abstract Datatypes: Terms}

More complicated examples of abstract datatypes may be given.  For
example, an abstract term structure may be defined as below
\begin{pvsexample}
  term [id, varid: TYPE] : DATATYPE
   BEGIN
    const(cid: id): const?
    variable(vid : varid) : var?
    lamb(bnd:(var?), body:term) : lamb?
    app(op: term, args: list[term]): app?
   END term
\end{pvsexample}
%
Note that the {\stt args} accessor is of type {\stt list[term]}.
There are restrictions on the types allowed for accessors; in this
case the only allowable types available for accessors involving the
type {\stt term} are: {\stt term}, {\stt list[term]}, {\stt
finite\_set[term]}, or {\stt sequence[term]}.  There is
no restriction on type expressions that do not reference {\stt term}.
Some of the axioms generated for abstract datatypes are modified when
accessors are of complex types; here, in particular, the induction axioms
and recursive combinators generated are modified to handle the list argument.

%\begin{pvsexample}
%stack_rec_mod[t: TYPE, range: TYPE]: THEORY
%  BEGIN
%   IMPORTING stack_adt[t]
%
%   stack_rec((emptystack?_fun: range),
%             (nonemptystack?_fun: [t, range -> range])):
%     [stack -> range] =
%     LAMBDA (stack_var: stack):
%       CASES stack_var OF
%         empty: emptystack?_fun,
%         push(push1_var, push2_var):
%             nonemptystack?_fun(push1_var,
%                                stack_rec(emptystack?_fun,
%                                          nonemptystack?_fun)
%                                  (push2_var))
%       ENDCASES
%     
%   END stack_rec_mod
%\end{pvsexample}

%The example of a table containing entries that are indexed by values
%provides an interesting example of a dependent type.  The required
%operations on a table are to be able to add and delete entries and to
%check whether there is an entry in the table corresponding to a given
%value.
%
%\begin{pvsexample}
%  tables [domain, range: type]: THEORY
%   BEGIN
%    table: TYPE = [\# dom: PRED[domain], 
%                     contents: [\{x:domain | dom(x)\} -> range] \#]
%    table((d:PRED[domain]),(c:[\{x:domain | d(x)\} -> range])):table =
%      (\# dom := d, contents := c \#)
%    apply((t:table),(x:\{e:domain | dom(t)(e)\})):range = contents(t)(x)
%    some\_range: range
%    empty\_table: table = table(lambda (e:domain):false,
%                               lambda (e:domain):some\_range)
%    every((p:PRED[range]),(t:table)):bool =
%      FORALL (x:{e:domain | dom(t)(e)}): p(contents(t)(x))
%    position: [PRED[range], t:table -> \{e:domain | dom(t)(e)\}]
%    position: AXIOM
%      FORALL (p:PRED[range]),(t:table):
%        ((EXISTS (x: \{e:domain | dom(t)(e)\}): p(contents(t)(x)))
%        IMPLIES
%       p(position(p,t)))
%    ran((t:table)):PRED[range] =
%      LAMBDA (r:range): 
%        EXISTS (x:\{e:domain | dom(t)(e)\}):
%          contents(t)(x) = r
%    image((t:table),(d:PRED[domain])):PRED[range] =
%      LAMBDA (r:range):
%        EXISTS (x:\{e:domain | dom(t)(e)\}):
%          (d(x) and contents(t)(x) = r)
%    maplet((e:domain),(r:range)):table =
%      table(LAMBDA (x:domain): x = e,
%            LAMBDA (x:domain): r)
%    update((t:table),(e:domain),(r:range)):table =
%      table(LAMBDA (x:domain): dom(t)(x) or x=e,
%            LAMBDA (x:\{s:domain | dom(t)(s) or s=e\}):
%              IF x = e THEN r ELSE contents(t)(x) ENDIF)
%    member\_update: LEMMA
%      FORALL (t:table),(e:domain),(r:range): dom(update(t,e,r))(e)
%   END tables
%\end{pvsexample}

%
%\begin{center}
%  {\stt pop(pop(push(push(elem, st))))}
%\end{center}
%since the result of the inner {\stt pop} has type {\stt stack} and
%not {\stt (nonemptystack?)}.  The \pvs\ typechecker would generate the
%proof obligation
%\begin{center}
%  {\stt nonemptystack?(pop(push(push(elem, st))))}
%\end{center}
%that is easily proved from the stack axioms.
%
%As is well known, the strong typing of higher-order logic is inflexible
%in certain ways.  A typical problem is the lack of type parametricity
%which requires, for instance, an identity function for each specific
%type.  This is handled in \pvs\ by explicitly allowing type
%parameters at the theory level.  Such a treatment of type parameters has
%the advantage of possessing a straightforward semantic explanation.
%
%Another problem with strongly typed systems is in their inability to
%handle partial operations such as division which are only defined on the
%positive natural numbers.  This is solved in \pvs\ by allowing the type of
%positive natural numbers to be defined by a set-like type construction,
%{\stt \{x:nat|x>0\}}.  The type of positive natural numbers is a subtype
%of the type of natural numbers and therefore is able to
%inherit properties.

%In addition to the basic types, and function types, \pvs\ also allows
%tuples, records, dependent tuples, records, and functions, and
%quotient types.  Such type constructors add enormous clarity and
%expressiveness to a specification language and a proper treatment of
%these entities is made possible by the viewpoint that typechecking
%can require theorem proving.
%
%In \pvs, specifications are packaged into theories (or modules).
%Theories can be parameterized by types, individuals, and other theories.
%A theory can build upon other theories so that it is possible to build a
%theory of ordered sets on top of a theory of sets and theories of
%orderings.  One theory can also implement another theory, and this is
%the basic mechanism for demonstrating the consistency of theories and
%for refining specifications to implementations.  There is a powerful
%datatype definition facility that can be used to automatically generate
%the axioms, induction scheme, and recursion combinators for a class of
%abstract datatypes.
%
%In summary, the \pvs\ language provides a comprehensive
%approach to writing, checking, and reusing specifications.
%A number of technical problems are solved by integrating theorem proving
%with typechecking.
%
%\subsection{Informal Syntax}
%
%We provide a readable description of the syntax of \pvs\ below.
%The precise grammar is described elsewhere.
%
%\subsection{Declarations}
%The units of specification in \pvs\ are declarations.
%Declarations can be used to either introduce names or
%import theories.  Declarations can introduce
%names for theories, assumptions, types, variables, constants,
%and formulas.  Declarations of types and constants can be definitions.
%An {\stt IMPORTING} declaration imports a theory.
%
%A theory declaration has the form:
%\begin{pvsexample}
% {\em name\/}  {\em theory-parameters\/} BEGIN {\em theory-body\/}
%END {\em name\/}
%\end{pvsexample}
%
%
%
%\subsection{Informal Semantics}
%
%We informally describe one intended semantics for \pvs\
%specifications, but it should be noted that this semantics
%is not necessarily the only desirable one.  The \pvs\ semantics
%is a ``loose'' one, \ie\ any interpretation of the types and
%constants that satisfies the axioms is considered acceptable.
%The semantics for the higher-order logic of \pvs\ is given by
%mapping well-formed type expressions to sets, and mapping
%well-formed terms of a given type to elements of the
%set corresponding to the type.
%
%It is then intended that in every model $\cal{M}$, the
%type {\stt bool} will be mapped to a two element set 
%$\{ {\bf true}, {\bf false} \}$, the type {\stt real} will
%be mapped to the set of reals, the type {\stt rational} will be mapped to
%the set of rationals, the type {\stt int} will be mapped to the integers,
%and the type {\stt nat} to the natural numbers.  We assume that there is
%a standard definition for these in the underlying set theory.
%The mapping for a type {\stt A} will be represented as $\dlb {\stt A} \drb$
%
%The singleton tuple type {\stt [A]} is mapped to $\dlb {\stt A}\drb$.
%The non-singleton tuple types of the form ${\stt [A_1,\ldots, A_n]}$ are
%mapped to the Cartesian product $\dlb {\stt A_1} \cross \ldots \cross
%{\stt A_n}\drb$.   A record type with $n$ fields is treated as an
%$n$-tuple with an order on the field names.
%
%The function type {\stt [A -> B]} is taken to be the set of all functions
%from $\dlb {\stt A} \drb$ to $\dlb {\stt B}\drb$.  There are of course
%many other reasonable interpretations of function types that do not
%include all the functions.  The minimal requirement on the
%interpretation of a function type is that should be closed under
%$\lambda$-abstraction in a way that will be described later.
%
%As seen above, the semantics of the primitive types, and the tuple,
%record, and function type constructions are easy to describe.
%We now need to pay attention to the fact that there could be
%uninterpreted type names in a type expression.  These get their meaning
%from a model $\cal{M}$ that maps type names to sets, and uninterpreted
%constants of a given type to an element of the set corresponding to that
%type.  Since both type expressions and terms can contain free variables,
%we need yet another parameter to the semantic definition, namely,
%an {\em assignment\/} that maps a free variable of a given type to
%an element of that type.  If $\rho$ is an assignment,
%$\update{\rho}{x}{a}$ represents the assignment that maps $x$ to $a$ and
%that behaves like $\rho$ otherwise.  The meaning of a type {\stt A} in a
%model $\cal{M}$ with respect to an assignment $\rho$ is denoted as
%$\interp{A}{TYPE}{\rho}$.  
%
%
%The predicate subtype {\stt \{x : A | p(x)\}} takes on the meaning
%$\{x\in \dlb {\stt A}\drb | \dlb p(x)\drb = {\bf true}\}$.
%
%The meaning of an expression $e$ of type $T$
%in a model $\cal{M}$ relative
%to an assignment $\rho$ is denoted by $\interp{e}{T}{\rho}$.
%The meaning of an individual constant $c$ is just $\cal{M}(c)$.
%Note that $\cal{M}$ contains distinct values {\bf true} and {\bf false}
%interpreting  the boolean
%constants {\sc true} and {\sc false}, respectively.  
%The meaning of an individual variable $x$ is just $\rho(x)$.
%The meaning of a lambda abstraction $(\lambda (x:S): e)$ of
%type $T$ is just a map from $\interp{S}{TYPE}{\rho}$ to
%$\interp{T}{TYPE}{\rho}$ where each element ${\bf a}$ in the former
%is mapped to the element $\interp{e}{T}{\rho\{x\gets {\bf a}\}}$
%in the latter.  The meaning of an application $f(e)$ is simply the
%result of applying map that is the meaning corresponding of $f$ to
%the meaning of $e$.  The meaning of an $n$-tuple  is given in
%terms of a set-theoretic $n$-tuple, and the projection functions
%are denoted by the corresponding projection operations in the set
%theory.  

